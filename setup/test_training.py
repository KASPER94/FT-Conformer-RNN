#!/usr/bin/env python3
"""
Script de test de fine-tuning avec donn√©es synth√©tiques
"""

import os
import sys
import json
import time
from pathlib import Path
import torch
import numpy as np
import librosa
import soundfile as sf
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn

console = Console()

def create_synthetic_dataset():
    """Cr√©er un petit dataset synth√©tique pour tester le training"""
    console.print("üé≠ Cr√©ation d'un dataset synth√©tique...", style="bold blue")
    
    # Vocabulaire ferroviaire fran√ßais
    cities = ["Lyon", "Paris", "Bordeaux", "Chalon", "Chauny", "Nogent"]
    train_types = ["TER", "TGV", "Intercit√©s"]
    actions = ["arrive", "part", "entre en gare", "dessert"]
    platforms = ["voie 1", "voie 2", "voie 3", "quai A", "quai B"]
    
    # Templates de phrases
    templates = [
        "Le {train_type} √† destination de {city} {action}",
        "Le train pour {city} {action} {platform}",
        "Correspondance pour {city}",
        "Prochain arr√™t {city}",
        "{train_type} {city} {platform}",
        "Attention le train √† destination de {city} va partir"
    ]
    
    dataset_dir = Path("data/synthetic_train")
    dataset_dir.mkdir(parents=True, exist_ok=True)
    
    manifests = {"train": [], "val": []}
    sample_rate = 16000
    
    console.print("üîÑ G√©n√©ration des √©chantillons...")
    
    # G√©n√©rer les √©chantillons
    total_samples = 50  # Petit dataset pour test
    train_samples = int(total_samples * 0.8)
    
    for i in range(total_samples):
        # Choisir split
        split = "train" if i < train_samples else "val"
        
        # G√©n√©rer phrase
        template = np.random.choice(templates)
        text = template.format(
            city=np.random.choice(cities),
            train_type=np.random.choice(train_types),
            action=np.random.choice(actions),
            platform=np.random.choice(platforms)
        )
        
        # Cr√©er audio synth√©tique
        duration = len(text) * 0.08 + np.random.uniform(0.5, 1.5)
        num_samples = int(sample_rate * duration)
        
        # Signal complexe simulant la parole
        t = np.linspace(0, duration, num_samples)
        
        # Fr√©quences fondamentales variables
        f0 = 150 + 50 * np.sin(2 * np.pi * 0.5 * t)  # Intonation
        
        # G√©n√©rer harmoniques
        signal = np.zeros(num_samples)
        for harmonic in range(1, 6):
            amplitude = 1.0 / harmonic
            signal += amplitude * np.sin(2 * np.pi * f0 * harmonic * t)
        
        # Modulation pour simuler syllables
        syllable_rate = len(text.split()) * 2 / duration  # ~2 syllabes par mot
        modulation = 1 + 0.4 * (np.sin(2 * np.pi * syllable_rate * t) > 0)
        signal *= modulation
        
        # Ajout de bruit l√©ger
        noise = np.random.normal(0, 0.05, signal.shape)
        signal += noise
        
        # Normalisation
        signal = signal / np.max(np.abs(signal)) * 0.8
        
        # Fade in/out
        fade_samples = int(0.01 * sample_rate)  # 10ms
        signal[:fade_samples] *= np.linspace(0, 1, fade_samples)
        signal[-fade_samples:] *= np.linspace(1, 0, fade_samples)
        
        # Sauvegarder
        audio_filename = f"synthetic_{split}_{i:03d}.wav"
        audio_path = dataset_dir / audio_filename
        sf.write(audio_path, signal, sample_rate)
        
        # Ajouter au manifest
        manifests[split].append({
            "audio_filepath": str(audio_path.absolute()),
            "text": text,
            "duration": duration
        })
    
    # Sauvegarder les manifests
    for split, manifest in manifests.items():
        manifest_path = Path("data/manifests") / f"{split}_manifest.json"
        manifest_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(manifest_path, 'w', encoding='utf-8') as f:
            for item in manifest:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
        
        console.print(f"‚úÖ {split}: {len(manifest)} √©chantillons -> {manifest_path}")
    
    return manifests

def create_training_config():
    """Cr√©er une configuration de training pour test"""
    console.print("‚öôÔ∏è Cr√©ation de la configuration de training...", style="bold blue")
    
    config = {
        "name": "ConformerRNNT_Test",
        "model": {
            "sample_rate": 16000,
            "train_ds": {
                "manifest_filepath": "data/manifests/train_manifest.json",
                "batch_size": 2,
                "shuffle": True,
                "num_workers": 2,
                "pin_memory": True,
                "max_duration": 20.0,
                "min_duration": 0.1
            },
            "validation_ds": {
                "manifest_filepath": "data/manifests/val_manifest.json", 
                "batch_size": 2,
                "shuffle": False,
                "num_workers": 2,
                "pin_memory": True
            },
            "optim": {
                "name": "adamw",
                "lr": 1e-4,
                "betas": [0.9, 0.98],
                "weight_decay": 1e-3,
                "sched": {
                    "name": "CosineAnnealing",
                    "warmup_steps": 100,
                    "warmup_ratio": None,
                    "min_lr": 1e-6
                }
            }
        },
        "trainer": {
            "devices": 1,
            "max_epochs": 3,
            "accelerator": "gpu" if torch.cuda.is_available() else "cpu",
            "strategy": "auto",
            "log_every_n_steps": 5,
            "val_check_interval": 20,
            "check_val_every_n_epoch": 1,
            "enable_checkpointing": True,
            "logger": False,  # D√©sactiver pour test
            "enable_model_summary": True
        }
    }
    
    config_path = Path("config/test_training_config.yaml")
    config_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Sauvegarder en YAML
    import yaml
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    console.print(f"‚úÖ Configuration sauvegard√©e: {config_path}")
    return config_path

def load_model_for_training():
    """Charger le mod√®le pr√©-entra√Æn√© pour le fine-tuning"""
    console.print("ü§ñ Chargement du mod√®le pour training...", style="bold blue")
    
    try:
        import nemo.collections.asr as nemo_asr
        
        # Chercher le mod√®le pr√©-entra√Æn√©
        model_dir = Path("models/pretrained")
        nemo_files = list(model_dir.glob("*.nemo"))
        
        if not nemo_files:
            console.print("‚ùå Mod√®le pr√©-entra√Æn√© non trouv√©")
            return None
        
        model_path = nemo_files[0]
        console.print(f"üìÇ Chargement depuis: {model_path}")
        
        # Charger le mod√®le
        model = nemo_asr.models.ASRModel.restore_from(str(model_path))
        
        # Configuration pour fine-tuning
        model.train()
        
        console.print("‚úÖ Mod√®le charg√© en mode training")
        return model
        
    except Exception as e:
        console.print(f"‚ùå Erreur chargement: {e}")
        return None

def test_data_loading(model, config_path):
    """Tester le chargement des donn√©es"""
    console.print("üìä Test du chargement de donn√©es...", style="bold blue")
    
    try:
        from omegaconf import OmegaConf
        
        # Charger la configuration
        cfg = OmegaConf.load(config_path)
        
        # Configurer les datasets
        model.setup_training_data(cfg.model.train_ds)
        model.setup_validation_data(cfg.model.validation_ds)
        
        # Tester un batch
        train_loader = model._train_dl
        val_loader = model._validation_dl
        
        console.print(f"‚úÖ Train loader: {len(train_loader)} batches")
        console.print(f"‚úÖ Val loader: {len(val_loader)} batches")
        
        # Tester le premier batch
        train_batch = next(iter(train_loader))
        console.print(f"‚úÖ Batch shape: {train_batch[0].shape}")
        console.print(f"‚úÖ Batch audio length: {train_batch[1].shape}")
        
        return True
        
    except Exception as e:
        console.print(f"‚ùå Erreur chargement donn√©es: {e}")
        return False

def test_forward_pass(model):
    """Tester le forward pass du mod√®le"""
    console.print("üîÑ Test du forward pass...", style="bold blue")
    
    try:
        # Cr√©er un batch factice
        batch_size = 2
        max_seq_len = 1000
        feat_dim = 80  # Dimension des features mel-spectrogram
        
        # Audio features (mel-spectrogram)
        audio_signal = torch.randn(batch_size, max_seq_len, feat_dim)
        audio_lengths = torch.tensor([max_seq_len, max_seq_len // 2])
        
        # Targets (tokenized text)
        max_target_len = 50
        targets = torch.randint(0, model.decoder.vocabulary_size, (batch_size, max_target_len))
        target_lengths = torch.tensor([max_target_len, max_target_len // 2])
        
        # Forward pass
        with torch.no_grad():
            loss, num_targets, prediction = model.forward(
                input_signal=audio_signal,
                input_signal_length=audio_lengths,
                targets=targets,
                target_length=target_lengths
            )
        
        console.print(f"‚úÖ Loss: {loss.item():.4f}")
        console.print(f"‚úÖ Num targets: {num_targets}")
        console.print(f"‚úÖ Forward pass r√©ussi")
        
        return True
        
    except Exception as e:
        console.print(f"‚ùå Erreur forward pass: {e}")
        return False

def run_mini_training(model, config_path):
    """Lancer un mini training de test"""
    console.print("üèÉ Lancement du mini training...", style="bold blue")
    
    try:
        import pytorch_lightning as pl
        from omegaconf import OmegaConf
        
        # Charger la configuration
        cfg = OmegaConf.load(config_path)
        
        # Configurer le mod√®le
        model.setup_training_data(cfg.model.train_ds)
        model.setup_validation_data(cfg.model.validation_ds)
        model.setup_optimization(cfg.model.optim)
        
        # Cr√©er le trainer
        trainer = pl.Trainer(
            max_epochs=1,  # Juste 1 epoch pour test
            devices=1,
            accelerator="gpu" if torch.cuda.is_available() else "cpu",
            log_every_n_steps=1,
            val_check_interval=5,
            enable_checkpointing=False,
            logger=False,
            enable_progress_bar=True
        )
        
        console.print("üîÑ D√©marrage du training test...")
        
        # Sauvegarder la loss initiale
        model.eval()
        with torch.no_grad():
            val_batch = next(iter(model._validation_dl))
            initial_loss = model.validation_step(val_batch, 0)
        
        console.print(f"üìä Loss initiale: {initial_loss:.4f}")
        
        # Training
        start_time = time.time()
        trainer.fit(model)
        training_time = time.time() - start_time
        
        # V√©rifier la loss finale
        model.eval()
        with torch.no_grad():
            final_loss = model.validation_step(val_batch, 0)
        
        console.print(f"üìä Loss finale: {final_loss:.4f}")
        console.print(f"üìä Diff√©rence: {initial_loss - final_loss:.4f}")
        console.print(f"‚è±Ô∏è Temps training: {training_time:.2f}s")
        
        # Sauvegarder le mod√®le fine-tun√©
        checkpoint_dir = Path("models/checkpoints")
        checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        checkpoint_path = checkpoint_dir / "test_finetuned.nemo"
        model.save_to(str(checkpoint_path))
        
        console.print(f"‚úÖ Mod√®le sauvegard√©: {checkpoint_path}")
        
        return True
        
    except Exception as e:
        console.print(f"‚ùå Erreur training: {e}")
        import traceback
        console.print(traceback.format_exc())
        return False

def test_inference_after_training():
    """Tester l'inf√©rence apr√®s fine-tuning"""
    console.print("üéØ Test d'inf√©rence post-training...", style="bold blue")
    
    try:
        import nemo.collections.asr as nemo_asr
        
        # Charger le mod√®le fine-tun√©
        checkpoint_path = Path("models/checkpoints/test_finetuned.nemo")
        
        if not checkpoint_path.exists():
            console.print("‚ùå Mod√®le fine-tun√© non trouv√©")
            return False
        
        model = nemo_asr.models.ASRModel.restore_from(str(checkpoint_path))
        model.eval()
        
        # Test avec phrase ferroviaire
        sample_rate = 16000
        duration = 2.0
        t = np.linspace(0, duration, int(sample_rate * duration))
        
        # Signal test avec patterns plus complexes
        signal = (np.sin(2 * np.pi * 200 * t) + 
                 0.5 * np.sin(2 * np.pi * 400 * t) +
                 0.3 * np.sin(2 * np.pi * 600 * t))
        
        # Modulation pour simuler "Lyon"
        signal *= (1 + 0.3 * np.sin(2 * np.pi * 3 * t))
        
        # Transcription
        transcription = model.transcribe([signal])
        
        console.print(f"‚úÖ Transcription test: '{transcription[0]}'")
        
        return True
        
    except Exception as e:
        console.print(f"‚ùå Erreur test inf√©rence: {e}")
        return False

def main():
    """Fonction principale"""
    console.print("üß™ Test de Fine-tuning Conformer RNN-T", style="bold")
    console.print("=" * 60)
    
    # √âtapes du test
    steps = [
        ("Cr√©ation dataset synth√©tique", create_synthetic_dataset),
        ("Configuration training", create_training_config),
        ("Chargement mod√®le", load_model_for_training),
    ]
    
    results = {}
    model = None
    config_path = None
    
    # Ex√©cuter les √©tapes pr√©paratoires
    for step_name, step_func in steps:
        console.print(f"\nüîÑ {step_name}...")
        try:
            if step_name == "Cr√©ation dataset synth√©tique":
                results[step_name] = step_func() is not None
            elif step_name == "Configuration training":
                config_path = step_func()
                results[step_name] = config_path is not None
            elif step_name == "Chargement mod√®le":
                model = step_func()
                results[step_name] = model is not None
                
        except Exception as e:
            console.print(f"‚ùå Erreur {step_name}: {e}")
            results[step_name] = False
    
    # Tests avec le mod√®le
    if model and config_path:
        training_steps = [
            ("Test chargement donn√©es", lambda: test_data_loading(model, config_path)),
            ("Test forward pass", lambda: test_forward_pass(model)),
            ("Mini training", lambda: run_mini_training(model, config_path)),
            ("Test inf√©rence post-training", test_inference_after_training)
        ]
        
        for step_name, step_func in training_steps:
            console.print(f"\nüîÑ {step_name}...")
            try:
                results[step_name] = step_func()
            except Exception as e:
                console.print(f"‚ùå Erreur {step_name}: {e}")
                results[step_name] = False
    
    # R√©sum√©
    console.print("\nüìã R√©sum√© du test de training:", style="bold")
    
    for step_name, success in results.items():
        status = "‚úÖ" if success else "‚ùå"
        console.print(f"  {status} {step_name}")
    
    success_count = sum(results.values())
    total_steps = len(results)
    
    console.print(f"\nüéØ Score: {success_count}/{total_steps} √©tapes r√©ussies")
    
    if success_count == total_steps:
        console.print("üéâ Pipeline de training fonctionnel!", style="bold green")
        console.print("\nüìù Prochaines √©tapes:")
        console.print("1. Pr√©parer vos vraies donn√©es audio")
        console.print("2. Ajuster la configuration pour votre dataset")
        console.print("3. Lancer le fine-tuning complet")
    else:
        console.print("‚ö†Ô∏è Certaines √©tapes ont √©chou√©.", style="bold yellow")
        console.print("V√©rifiez les logs pour diagnostiquer les probl√®mes.")
    
    return success_count == total_steps

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)