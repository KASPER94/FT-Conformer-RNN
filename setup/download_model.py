#!/usr/bin/env python3
"""
Script de t√©l√©chargement du mod√®le Conformer RNN-T pr√©-entra√Æn√©
"""

import os
import sys
from pathlib import Path
import torch
from rich.console import Console
from rich.progress import Progress, TextColumn, BarColumn, TimeRemainingColumn

console = Console()

def download_pretrained_model():
    """T√©l√©charger le mod√®le pr√©-entra√Æn√© NVIDIA"""
    console.print("üì• T√©l√©chargement du mod√®le Conformer RNN-T...", style="bold blue")
    
    try:
        import nemo.collections.asr as nemo_asr
        
        # Mod√®les disponibles (du plus petit au plus grand)
        models = {
            "small": "stt_conformer_rnnt_small",
            "medium": "stt_conformer_rnnt_medium", 
            "large": "stt_conformer_rnnt_large"
        }
        
        console.print("Mod√®les disponibles:")
        for size, model_name in models.items():
            console.print(f"  - {size}: {model_name}")
        
        # Commencer par le mod√®le medium pour les tests
        model_name = models["medium"]
        console.print(f"\nüîÑ T√©l√©chargement de {model_name}...")
        
        # T√©l√©charger le mod√®le
        model = nemo_asr.models.ASRModel.from_pretrained(model_name)
        
        # Sauvegarder localement
        model_path = Path("models/pretrained")
        model_path.mkdir(parents=True, exist_ok=True)
        
        local_path = model_path / f"{model_name}.nemo"
        model.save_to(str(local_path))
        
        console.print(f"‚úÖ Mod√®le sauvegard√©: {local_path}", style="bold green")
        
        # Afficher les informations du mod√®le
        console.print("\nüìä Informations du mod√®le:")
        console.print(f"  - Architecture: {model.__class__.__name__}")
        console.print(f"  - Vocabulaire: {model.decoder.vocabulary}")
        console.print(f"  - Sample rate: {model._cfg.sample_rate}Hz")
        
        return model, str(local_path)
        
    except Exception as e:
        console.print(f"‚ùå Erreur lors du t√©l√©chargement: {e}", style="bold red")
        return None, None

def verify_model_components(model):
    """V√©rifier les composants du mod√®le"""
    console.print("\nüîç V√©rification des composants du mod√®le...")
    
    try:
        # V√©rifier l'encodeur
        if hasattr(model, 'encoder'):
            console.print("‚úÖ Encodeur Conformer pr√©sent")
        else:
            console.print("‚ùå Encodeur manquant")
            
        # V√©rifier le d√©codeur RNN-T
        if hasattr(model, 'decoder'):
            console.print("‚úÖ D√©codeur RNN-T pr√©sent")
        else:
            console.print("‚ùå D√©codeur manquant")
            
        # V√©rifier le joint network
        if hasattr(model, 'joint'):
            console.print("‚úÖ Joint Network pr√©sent")
        else:
            console.print("‚ùå Joint Network manquant")
            
        return True
        
    except Exception as e:
        console.print(f"‚ùå Erreur lors de la v√©rification: {e}")
        return False

def test_model_inference(model):
    """Tester l'inf√©rence avec un signal audio factice"""
    console.print("\nüß™ Test d'inf√©rence avec signal audio factice...")
    
    try:
        # Cr√©er un signal audio factice (16kHz, 2 secondes)
        sample_rate = 16000
        duration = 2.0
        num_samples = int(sample_rate * duration)
        
        # Signal sinuso√Ødal simple
        import torch
        import numpy as np
        
        t = np.linspace(0, duration, num_samples)
        # M√©lange de fr√©quences pour simuler de la parole
        signal = (np.sin(2 * np.pi * 200 * t) + 
                 0.5 * np.sin(2 * np.pi * 400 * t) + 
                 0.3 * np.sin(2 * np.pi * 800 * t))
        
        # Ajouter un peu de bruit
        noise = np.random.normal(0, 0.1, signal.shape)
        signal = signal + noise
        
        # Normaliser
        signal = signal / np.max(np.abs(signal))
        
        console.print(f"‚úÖ Signal audio cr√©√©: {duration}s, {sample_rate}Hz")
        
        # Test d'inf√©rence
        with torch.no_grad():
            transcription = model.transcribe([signal])
            
        console.print(f"‚úÖ Inf√©rence r√©ussie")
        console.print(f"  - Transcription (signal factice): '{transcription[0]}'")
        
        return True
        
    except Exception as e:
        console.print(f"‚ùå Erreur lors du test d'inf√©rence: {e}")
        return False

def save_model_info(model, model_path):
    """Sauvegarder les informations du mod√®le"""
    console.print("\nüíæ Sauvegarde des informations du mod√®le...")
    
    try:
        import json
        
        model_info = {
            "model_name": model.__class__.__name__,
            "model_path": model_path,
            "vocabulary": list(model.decoder.vocabulary),
            "sample_rate": model._cfg.sample_rate,
            "config": model._cfg if hasattr(model, '_cfg') else {}
        }
        
        info_path = Path("models/pretrained/model_info.json")
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(model_info, f, indent=2, ensure_ascii=False)
            
        console.print(f"‚úÖ Informations sauvegard√©es: {info_path}")
        
        return True
        
    except Exception as e:
        console.print(f"‚ùå Erreur sauvegarde info: {e}")
        return False

def main():
    """Fonction principale"""
    console.print("ü§ñ T√©l√©chargement et test du mod√®le Conformer RNN-T", style="bold")
    console.print("=" * 60)
    
    # T√©l√©charger le mod√®le
    model, model_path = download_pretrained_model()
    if model is None:
        console.print("‚ùå √âchec du t√©l√©chargement", style="bold red")
        return False
    
    # V√©rifier les composants
    if not verify_model_components(model):
        console.print("‚ùå Composants du mod√®le invalides", style="bold red")
        return False
    
    # Tester l'inf√©rence
    if not test_model_inference(model):
        console.print("‚ùå Test d'inf√©rence √©chou√©", style="bold red")
        return False
    
    # Sauvegarder les infos
    save_model_info(model, model_path)
    
    console.print("\nüéâ Mod√®le t√©l√©charg√© et test√© avec succ√®s!", style="bold green")
    console.print("\n√âtapes suivantes:")
    console.print("1. Tester avec de l'audio r√©el: python scripts/03_test_inference.py")
    console.print("2. Pr√©parer vos donn√©es: python scripts/04_prepare_data.py")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)