# ğŸš‚ Projet ASR Ferroviaire - Conformer RNN-T

Ce projet implÃ©mente un systÃ¨me de reconnaissance vocale automatique (ASR) basÃ© sur l'architecture **Conformer RNN-T** de NVIDIA, spÃ©cialement fine-tunÃ© pour le domaine ferroviaire franÃ§ais.

## ğŸ¯ Objectifs

- **Reconnaissance vocale temps rÃ©el** pour annonces ferroviaires
- **Vocabulaire spÃ©cialisÃ©** : noms de villes franÃ§aises, terminologie SNCF
- **Streaming capability** : latence faible pour applications en direct
- **Robustesse** : fonctionnement dans environnement bruitÃ© (gares, trains)

## ğŸ—ï¸ Architecture

### Pourquoi Conformer RNN-T ?

**Conformer** combine les avantages de :
- **Transformers** : Attention globale pour capturer les dÃ©pendances long-terme
- **CNN** : Patterns locaux pour les caractÃ©ristiques phonÃ©tiques
- **Architecture hybride** optimale pour la reconnaissance vocale

**RNN-Transducer** permet :
- **Streaming natif** : dÃ©codage incrÃ©mental pendant que l'audio arrive
- **Latence faible** : pas d'attente de fin d'Ã©noncÃ©
- **Gestion intelligente des silences** via le mÃ©canisme de "blank token"

### Structure du Projet

```
railway_asr_project/
â”œâ”€â”€ src/                    # Code source principal
â”‚   â”œâ”€â”€ models/            # ModÃ¨les et architectures
â”‚   â”œâ”€â”€ data/              # Gestion des donnÃ©es
â”‚   â”œâ”€â”€ training/          # Pipeline d'entraÃ®nement
â”‚   â””â”€â”€ inference/         # SystÃ¨me d'infÃ©rence
â”œâ”€â”€ scripts/               # Scripts d'installation et test
â”œâ”€â”€ config/                # Configurations YAML
â”œâ”€â”€ data/                  # DonnÃ©es d'entraÃ®nement
â””â”€â”€ models/                # ModÃ¨les sauvegardÃ©s
```

## ğŸš€ Installation Rapide

### 1. Configuration de l'environnement

```bash
# Cloner le projet
git clone <repo-url>
cd railway_asr_project

# Installer les dÃ©pendances
pip install -r requirements.txt

# Configurer l'environnement
python scripts/01_setup_environment.py
```

### 2. TÃ©lÃ©chargement du modÃ¨le prÃ©-entraÃ®nÃ©

```bash
python scripts/02_download_model.py
```

### 3. Tests de fonctionnement

```bash
# Test d'infÃ©rence
python scripts/03_test_inference.py

# Test de fine-tuning
python scripts/05_test_training.py
```

## ğŸ“Š Dataset RecommandÃ©

### SpÃ©cifications

- **Volume minimum** : 8-12 heures d'audio
- **Locuteurs** : 15-25 personnes (hommes/femmes, Ã¢ges variÃ©s)
- **QualitÃ© audio** : 16kHz, mono, WAV
- **Contenu** : Phrases ferroviaires avec noms de villes franÃ§aises

### Exemples de Phrases

```
"Le TER Ã  destination de Lyon partira voie 3"
"Correspondance pour Chalon-sur-SaÃ´ne"
"Prochain arrÃªt Chauny"
"Le train pour Bordeaux entre en gare"
"Attention Ã  Nogent-le-Rotrou, terminus"
```

### Vocabulaire Cible

**Villes franÃ§aises** : Lyon, Paris, Bordeaux, Chalon-sur-SaÃ´ne, Chauny, Nogent-le-Rotrou, Roanne, Saint-Ã‰tienne...

**Terminologie ferroviaire** : TER, TGV, IntercitÃ©s, correspondance, terminus, quai, voie, desserte, omnibus...

## ğŸ›ï¸ Configuration

### ParamÃ¨tres de Training

```yaml
model:
  name: "stt_conformer_rnnt_large"
  sample_rate: 16000
  
training:
  batch_size: 8-16
  learning_rate: 1e-4 Ã  5e-5
  max_epochs: 10-50
  
data:
  max_duration: 20.0
  min_duration: 0.5
  augmentation: true
```

### Fine-tuning Strategy

1. **Phase 1** : Gel des couches basses, fine-tuning des couches hautes
2. **Phase 2** : Fine-tuning complet avec learning rate rÃ©duit
3. **Phase 3** : Optimisation spÃ©cifique au domaine

## ğŸ”§ Utilisation

### InfÃ©rence Simple

```python
import nemo.collections.asr as nemo_asr

# Charger le modÃ¨le fine-tunÃ©
model = nemo_asr.models.ASRModel.restore_from("models/final/railway_model.nemo")

# Transcription
transcription = model.transcribe(["path/to/audio.wav"])
print(transcription[0])
```

### Streaming en Temps RÃ©el

```python
from src.inference.streaming import StreamingASR

# Initialiser le systÃ¨me streaming
asr = StreamingASR("models/final/railway_model.nemo")

# Traitement en chunks
for audio_chunk in audio_stream:
    partial_transcript = asr.process_chunk(audio_chunk)
    print(f"Transcription partielle: {partial_transcript}")
```

## ğŸ“ˆ Performance Attendue

### MÃ©triques

- **WER (Word Error Rate)** : < 5% sur donnÃ©es ferroviaires
- **Latence** : < 200ms pour streaming
- **RTF (Real-Time Factor)** : < 0.3 sur GPU moderne
- **Couverture vocabulaire** : > 95% termes ferroviaires franÃ§ais

### Benchmarks

| DurÃ©e Audio | Temps Process | RTF | Performance |
|-------------|---------------|-----|-------------|
| 1.0s        | 0.1s         | 0.1 | ğŸš€ Excellent |
| 5.0s        | 0.8s         | 0.16| âœ… Bon       |
| 10.0s       | 2.1s         | 0.21| âœ… Bon       |

## ğŸ”„ Pipeline de DÃ©veloppement

### 1. PrÃ©paration des DonnÃ©es

```bash
# PrÃ©parer le dataset
python scripts/04_prepare_data.py --input_dir data/raw --output_dir data/processed

# VÃ©rifier la qualitÃ©
python scripts/06_evaluate_model.py --mode data_quality
```

### 2. Fine-tuning

```bash
# Lancer l'entraÃ®nement
python -m src.training.trainer --config config/training_config.yaml

# Monitoring
tensorboard --logdir logs/tensorboard
```

### 3. Ã‰valuation

```bash
# Test sur donnÃ©es de validation
python scripts/06_evaluate_model.py --model_path models/checkpoints/best.nemo

# Test streaming
python scripts/03_test_inference.py --streaming
```

## ğŸ­ Voice Cloning (Bonus)

Le dataset peut Ãªtre rÃ©utilisÃ© pour crÃ©er des voix synthÃ©tiques :

### PrÃ©requis Voice Cloning

- **Locuteur principal** : 60-90 minutes d'audio
- **QualitÃ© constante** : mÃªme microphone, environnement
- **DiversitÃ© prosodique** : questions, affirmations, urgence

### Pipeline TTS

```python
# AprÃ¨s fine-tuning ASR, utiliser pour TTS
from src.models.voice_cloning import RailwayTTS

tts = RailwayTTS("models/voice_clone/speaker_001.nemo")
audio = tts.synthesize("Le train Ã  destination de Lyon va partir")
```

## ğŸ› ï¸ Scripts Disponibles

| Script | Description |
|--------|-------------|
| `01_setup_environment.py` | Configuration initiale |
| `02_download_model.py` | TÃ©lÃ©chargement modÃ¨le prÃ©-entraÃ®nÃ© |
| `03_test_inference.py` | Tests d'infÃ©rence et streaming |
| `04_prepare_data.py` | PrÃ©paration du dataset |
| `05_test_training.py` | Test de fine-tuning |
| `06_evaluate_model.py` | Ã‰valuation et mÃ©triques |

## ğŸ“‹ Checklist de DÃ©ploiement

### Avant Production

- [ ] Dataset de 8+ heures validÃ©
- [ ] Fine-tuning convergÃ© (WER < 5%)
- [ ] Tests streaming rÃ©ussis (latence < 200ms)
- [ ] Vocabulaire ferroviaire couvert (> 95%)
- [ ] Tests en environnement bruitÃ©
- [ ] Validation sur voix non vues

### Optimisations Production

- [ ] Quantization du modÃ¨le (FP16/INT8)
- [ ] Optimisation TensorRT
- [ ] Cache des modÃ¨les
- [ ] Monitoring temps rÃ©el
- [ ] Fallback en cas d'Ã©chec

## ğŸ” Troubleshooting

### ProblÃ¨mes Courants

**CUDA Out of Memory**
```bash
# RÃ©duire batch_size dans config
batch_size: 4  # au lieu de 8
```

**Convergence lente**
```bash
# Ajuster learning rate
learning_rate: 5e-5  # au lieu de 1e-4
```

**Mauvaise reconnaissance des villes**
```bash
# Augmenter donnÃ©es spÃ©cifiques
python scripts/04_prepare_data.py --focus_cities Lyon,Bordeaux,Chalon
```

## ğŸ“š Ressources

### Documentation

- [NVIDIA NeMo Documentation](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/)
- [Conformer Paper](https://arxiv.org/abs/2005.08100)
- [RNN-T Architecture](https://arxiv.org/abs/1211.3711)

### ModÃ¨les PrÃ©-entraÃ®nÃ©s

- `stt_conformer_rnnt_small` : ModÃ¨le lÃ©ger, rapide
- `stt_conformer_rnnt_medium` : Bon compromis performance/vitesse
- `stt_conformer_rnnt_large` : Meilleure qualitÃ©, plus lent

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/amelioration`)
3. Commit les changements (`git commit -am 'Ajout fonctionnalitÃ©'`)
4. Push vers la branche (`git push origin feature/amelioration`)
5. CrÃ©er une Pull Request

## ğŸ“„ License

Ce projet est sous licence MIT. Voir `LICENSE` pour plus de dÃ©tails.

## ğŸ™ Remerciements

- **NVIDIA** pour les modÃ¨les NeMo prÃ©-entraÃ®nÃ©s
- **Ã‰quipe Conformer** pour l'architecture innovante
- **CommunautÃ© ASR** pour les contributions open source

---

**ğŸš€ PrÃªt Ã  commencer ?**

```bash
python scripts/01_setup_environment.py
```

Pour toute question : [Issues GitHub](link-to-issues) | [Documentation](link-to-docs)